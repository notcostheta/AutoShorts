import pandas as pd


def clean_word_df(word_df):
    """
    Cleans the DataFrame by merging words with NaN start times with the previous word.
    """
    # Iterate over the DataFrame rows
    for index, row in word_df.iterrows():
        if (
            pd.isna(row["start"]) and index > 0
        ):  # Check for NaN and ensure not the first row
            # Merge this word with the previous word
            word_df.at[index - 1, "word"] += " " + row["word"]
    # Drop rows with NaN in 'start' column
    return word_df.dropna(subset=["start"])


def process_all_iterations(data):
    """
    Processes all iterations in the data, cleaning each DataFrame.
    """
    cleaned_data = []
    for iteration in data["words"]:
        temp_word_df = pd.DataFrame(iteration)
        cleaned_df = clean_word_df(temp_word_df)
        cleaned_data.append(cleaned_df)
    return cleaned_data


def fix_start_end(data, cleaned_iterations):
    """
    Adjusts the start and end times of each iteration based on the 'end' times in the data.
    """
    end_list = data["end"].tolist()
    for i, iteration in enumerate(cleaned_iterations):
        if i > 0:
            iteration["start"] = iteration["start"].apply(lambda x: x - end_list[i - 1])
            iteration["end"] = iteration["end"].apply(lambda x: x - end_list[i - 1])


def fix_timings(dataframe):
    """
    Driver function that takes a DataFrame object and returns a list of cleaned DataFrame objects.
    """
    # Ensure 'words' and 'end' keys exist in the DataFrame
    if "words" in dataframe and "end" in dataframe:
        cleaned_iterations = process_all_iterations(dataframe)
        fix_start_end(dataframe, cleaned_iterations)
        return cleaned_iterations
    else:
        raise ValueError("Input DataFrame must contain 'words' and 'end' keys.")


# Example usage
# data = pd.read_json("transformed__.json")
# cleaned_dataframes = fix_timings(data)
# Now `cleaned_dataframes` contains the list of cleaned DataFrame objects


def format_timestamp(seconds):
    """Convert seconds to ASS timestamp format."""
    milliseconds = int((seconds % 1) * 100)
    seconds = int(seconds)
    minutes, seconds = divmod(seconds, 60)
    hours, minutes = divmod(minutes, 60)
    return f"{hours:01}:{minutes:02}:{seconds:02}.{milliseconds:02}"


def group_words(words, max_words=4):
    """Group words into segments with a maximum of max_words each."""
    grouped_words = []
    current_group = []
    for word in words:
        if len(current_group) < max_words:
            current_group.append(word)
        else:
            grouped_words.append(current_group)
            current_group = [word]
    if current_group:
        grouped_words.append(current_group)
    return grouped_words


def group_words_from_df(df, max_words=4):
    """Group words into segments with a maximum of max_words each, from a DataFrame."""
    words = df.to_dict("records")  # Convert DataFrame to list of dicts
    return group_words(words, max_words)


def create_ass_from_dfs(dfs, output_folder="output", max_words=4):
    """Create ASS files from a list of pandas DataFrames."""
    for i, df in enumerate(dfs):
        filename = f"{output_folder}/{i}.ass"
        grouped_words = group_words_from_df(df, max_words)

        with open(filename, "w") as f:
            # Write ASS header and other static parts as before
            f.write("[Script Info]\n")
            f.write("; Script generated by Aegisub 3.2.2\n")
            f.write("; http://www.aegisub.org/\n")
            f.write("Title: Word-level Subtitles\n")
            f.write("ScriptType: v4.00+\n")
            f.write("WrapStyle: 0\n")
            f.write("ScaledBorderAndShadow: yes\n")
            # f.write("Collisions: Normal\n")
            f.write("PlayDepth: 0\n")
            f.write("Timer: 100.0000\n")
            f.write("YCbCr Matrix: TV.601\n")
            f.write("PlayResX: 1920\n")
            f.write("PlayResY: 1080\n\n")

            f.write("[V4+ Styles]\n")
            f.write(
                "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, "
                "Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, "
                "Alignment, MarginL, MarginR, MarginV, Encoding\n"
            )
            f.write(
                "Style: Default,Arial,200,&H00FFFFFF,&H00FFFFFF,&H00000000,&H64000000,-1,0,0,0,50,50,0,0,1,12,0,8,10,10,0,1\n\n"
            )

            f.write("[Events]\n")
            f.write(
                "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n"
            )

            # Write each subtitle entry
            for group in grouped_words:
                start = format_timestamp(group[0]["start"])
                end = format_timestamp(group[-1]["end"])
                text = " ".join(word_info["word"] for word_info in group)
                f.write(f"Dialogue: 0,{start},{end},Default,,0,0,810,,{text}\n")


# Example usage
# create_ass_from_dfs(dfs, output_folder="subtitles", max_words=1)
